# Week 1 ARTS
### [Algorithm] - LC: Number of Connected Components in an Undirectly Graph (Java)
------
### Solution: [Union Find](https://www.wikiwand.com/en/Disjoint-set_data_structure)
Steps:
* Union all nodes into components
* Find number of components
```java
/**
 * Given n nodes labeled from 0 to n - 1 and a list of undirected edges (each edge is a pair of nodes),
 * write a function to find the number of connected components in an undirected graph.
 *
 * Example 1:
 *
 *      0          3
 *
 *      |          |
 *
 *      1 --- 2    4
 *
 * Given n = 5 and edges = [[0, 1], [1, 2], [3, 4]], return 2.
 *
 * Example 2:
 *
 *      0           4
 *
 *      |           |
 *
 *      1 --- 2 --- 3
 *
 * Given n = 5 and edges = [[0, 1], [1, 2], [2, 3], [3, 4]], return 1.
 *
 *  Note:
 *
 * You can assume that no duplicate edges will appear in edges. Since all edges are undirected,
 * [0, 1] is the same as [1, 0] and thus will not appear together in edges.
 */
 
 public class NumberOfConnectedComponents {
  public int countComponents_uf(int n, int[][] edges) {
    // Initial parents
    int[] parents = new int[n];
    for (int i = 0; i < n; i++) {
      parents[i] = i;
    }
    // Union nodes 
    for (int[] edge : edges) {
      union(parents, edge[0], edge[1]); 
    }
    // find number of connected components (number of different parents), using Set
    Set<Integer> numOfComp = new HashSet<>();
    for (int i = 0; i < n; i++) {
      set.add(find(parents, i));
    }
    
    return set.size();
  }
  
  // find node
  public int find(int[] parents, int node) {
    if (parents[node] == node) return node;
    return find(parents, parents[node]);
  }
  
  // union nodes
  public void union(int[] parents, int n1, int n2) {
    int np1 = find(parents, n1);
    int np2 = find(parents, n2);
    parents[np1] = np2;
  }
 }
```
*Recommendation* : Learned Union Find algorithm though on [Coursera Algorithms Part I](https://www.coursera.org/learn/algorithms-part1) [Coursera Algorithms Part II](https://www.coursera.org/learn/algorithms-part2) by Princeton University. Highly Recommend this course, and it is free, hahaha.

Usually when I saw a graph relate problem, first solution came to mind is using DFS or BFS. For this question, we can also sovle it by DFS / BFS, and I think UF solution is much more elegant.

#### Follow up 
Input is a data steam, how to handle?

Thoughts:
Using Map Reduce 

### [Review] - Cache
------
Recently I experimented with Hibernate Cache and CouchBase Cache, so today will review some caches, no matter it is distributed cache or local cache or Hibernate Cache, it is all about cache today. So today I will start some cache journeys.

As we all know cache is very important, we need to reduce Database hit as much as we can. So we're trying everything we can to add different layer caching.
Before hiting local Hibernate second level cache (here I experimented with Hibernate EHCache), we also added local EHCache per region and distributed Couchbase cache before local Hibernate EHCache. And we need to think carefully TTL(time to live) and MaxElementsInMemory. 
> Note: Caching is great, but it is better to cache non-transactional and read-only data

* [Hibernate Caching](https://www.tutorialspoint.com/hibernate/hibernate_caching.htm)
* [All about Hibernate second cache](https://dzone.com/articles/all-about-hibernate-second)
* [High performance with Distributed Caching Couchbase](http://info.couchbase.com/rs/302-GJY-034/images/High_Performance_With_Distributed_Caching_Couchbase.pdf)

### [Tips] - 
------
If you are using [statsD](https://github.com/etsy/statsd) to collect and report metrics and submitting to [DataDog](https://github.com/datadog) for monitoring, I'd like to share some tips on how to avoid naming conflicts on DD UI issues. 

1. When using statsd to collect and report your metrics, better to use different names for different type metrics.
> e.g `count` and `time` type, there are conflicts visualization on DD UI, because count and time are sharing the same name, name for count and time displaying on DD UI is `[metrics name].count`.
> e.g 'distribution' (for global application level metrics) and 'gauge' types, will share the same name. 

2. Config datadog.yaml config file for your histogram, need to explictly add histogram aggregation types. 
> histogram_aggregates: ["max", "median", "avg", "count"] 
histogram_percentiles: ["0.95"]

3. Check Datadog status and information

`/usr/local/bin/datadog-agent status`

`/usr/local/bin/datadog-agent info`

> addition tip for Datadog Agent v6 launch GUI: default 5002
`datadog-agent launch-gui`


### [Share] - Helm
------
Today I want to share a very useful [Kubernetes](https://github.com/kubernetes/kubernetes) cluster tool - [Helm](https://github.com/kubernetes/helm)
* [Helm package Management](https://medium.com/@gajus/the-missing-ci-cd-kubernetes-component-helm-package-manager-1fe002aac680)
Helm provides a convenient wrapper around `kubectl` which groups a bunch of resources together into helm `release`. this bunlding allows us to easily takedown or rollback of a like set of resources instead of having to track your ConfigMap, Deployment, and Service independently. In additionally, Helm supports the [Go Templating](https://golang.org/pkg/text/template/) in resource YAML files to config deployments per environment basis.

#### Installation
Recommand using `brew` install helm.

`brew install kubernetes-helm`
> Note: You might get Error: incompatible versions client[v2.9.0] server[v2.8.0]
In this case, your local version is higher (and brew is always install the latest version of helm), you can install the old version of helm and using `brew switch kubernetes-helm version` to match your server version.

#### Update helm tiller
To update tiller deployment, simply run the following command line in each environment
`helm init --upgrade` (assume you using `brew` install helm)


